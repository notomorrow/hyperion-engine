#version 450
#extension GL_GOOGLE_include_directive : require

#include "ssr_header.inc"
#include "../include/noise.inc"
#include "../include/brdf.inc"

HYP_DESCRIPTOR_UAV(SSRDescriptorSet, UVImage, format = rgba16f) uniform writeonly image2D ssr_uvs;
HYP_DESCRIPTOR_CBUFF(SSRDescriptorSet, SSRParams, size = 64) uniform SSRParamsBuffer
{
	uvec4 dimension;
	float ray_step;
	float num_iterations;
	float max_ray_distance;
	float distance_bias;
	float offset;
	float eye_fade_start;
	float eye_fade_end;
	float screen_edge_fade_start;
	float screen_edge_fade_end;
} ssr_params;

HYP_DESCRIPTOR_SRV(Global, GBufferTextures, count = 8) uniform texture2D gbuffer_textures[8];
HYP_DESCRIPTOR_SRV(Global, GBufferDepthTexture) uniform texture2D gbuffer_depth_texture;
HYP_DESCRIPTOR_SAMPLER(Global, SamplerNearest) uniform sampler sampler_nearest;
HYP_DESCRIPTOR_SAMPLER(Global, SamplerLinear) uniform sampler sampler_linear;
HYP_DESCRIPTOR_SSBO(Global, BlueNoiseBuffer, size = 1310720) readonly buffer BlueNoiseBuffer
{
	ivec4 sobol_256spp_256d[256 * 256 / 4];
	ivec4 scrambling_tile[128 * 128 * 8 / 4];
	ivec4 ranking_tile[128 * 128 * 8 / 4];
};

HYP_DESCRIPTOR_SSBO_DYNAMIC(Scene, ScenesBuffer, size = 256) readonly buffer SceneBuffer
{
    Scene scene;
};

HYP_DESCRIPTOR_CBUFF_DYNAMIC(Scene, CamerasBuffer, size = 512) uniform CameraShaderData
{
    Camera camera;
};

#define HYP_DO_NOT_DEFINE_DESCRIPTOR_SETS
#include "../include/gbuffer.inc"
#include "../include/BlueNoise.glsl"
#undef HYP_DO_NOT_DEFINE_DESCRIPTOR_SETS

mat4 view = camera.view;
mat4 proj = camera.projection;
mat4 inverse_proj = inverse(proj);
mat4 inverse_view = inverse(view);

bool TraceRays(
    vec3 ray_origin,
    vec3 ray_direction,
    out vec2 hit_pixel,
    out vec3 hit_point,
    out float hit_weight,
    out float num_iterations
)
{
    bool intersect = false;
    num_iterations = 0.0;
    hit_weight = 0.0;
    hit_pixel = vec2(0.0);
    hit_point = vec3(0.0);

    vec3 ray_step = ssr_params.ray_step * normalize(ray_direction);
    vec3 marching_position = ray_origin;
    float depth_from_screen;
    float step_delta;

    vec4 view_space_position;

    int i = 0;

    for (; i < ssr_params.num_iterations; i++) {
        marching_position += ray_step;

        hit_pixel = GetProjectedPositionFromView(proj, marching_position);
        view_space_position = ReconstructViewSpacePositionFromDepth(inverse_proj, hit_pixel, Texture2D(sampler_nearest, gbuffer_depth_texture, hit_pixel).r);

        step_delta = marching_position.z - view_space_position.z;

        intersect = step_delta > 0.0;
        num_iterations += 1.0;

        if (intersect) {
            break;
        }
    }

    if (intersect) {
        // binary search
        for (; i < ssr_params.num_iterations; i++) {
            ray_step *= 0.5;
            marching_position = marching_position - ray_step * sign(step_delta);

            hit_pixel = GetProjectedPositionFromView(proj, marching_position);
            view_space_position = ReconstructViewSpacePositionFromDepth(inverse_proj, hit_pixel, Texture2D(sampler_nearest, gbuffer_depth_texture, hit_pixel).r);
            
            step_delta = abs(marching_position.z) - view_space_position.z;

            if (abs(step_delta) < ssr_params.distance_bias) {
                return true;
            }
        }
    }

    return false;
}

float CalculateAlpha(
    float num_iterations,
    vec2 hit_pixel,
    vec3 hit_point,
    float dist,
    vec3 ray_direction
)
{
    float alpha = 1.0;
    // Fade ray hits that approach the maximum iterations
    alpha *= 1.0 - (num_iterations / ssr_params.num_iterations);

    // Fade ray hits that approach the screen edge
    vec2 hit_pixel_ndc = hit_pixel * 2.0 - 1.0;
    float max_dimension = saturate(max(abs(hit_pixel_ndc.x), abs(hit_pixel_ndc.y)));
    // alpha *= 1.0 - max(0.0, max_dimension - ssr_params.screen_edge_fade_start) / (1.0 - ssr_params.screen_edge_fade_end);

    alpha = 1.0 - smoothstep(0.02, 0.99, max_dimension);

    return alpha;
}

void main(void)
{
    // Checkerboard pattern -- we dispatch half the number of threads as the image resolution,
    // and alternate between even and odd pixels each frame.
    const uint pixel_index = (gl_GlobalInvocationID.x * 2) + (scene.frame_counter & 1);
    const uvec2 coord = uvec2(
        pixel_index % ssr_params.dimension.x,
        pixel_index / ssr_params.dimension.x
    );

    if (any(greaterThanEqual(coord, ssr_params.dimension.xy))) {
        return;
    }

    vec2 texcoord = saturate((vec2(coord) + 0.5) / (vec2(ssr_params.dimension.xy)));

    const vec4 material_info = Texture2D(sampler_nearest, gbuffer_material_texture, texcoord);
    const float roughness = material_info.r;
    const float depth = Texture2D(sampler_nearest, gbuffer_depth_texture, texcoord).r;

    if (depth > 0.9995) {
        imageStore(ssr_uvs, ivec2(coord), vec4(0.0));
        return;
    }

    vec3 N = DecodeNormal(Texture2D(sampler_nearest, gbuffer_normals_texture, texcoord));

    vec3 P = ReconstructViewSpacePositionFromDepth(inverse_proj, texcoord, depth).xyz;
    vec3 V = normalize(vec3(0.0) - P);
    vec3 view_space_normal = (view * vec4(N, 0.0)).xyz;

    // vec4 world_space_position = (inverse_view * vec4(P, 1.0));
    // world_space_position /= world_space_position.w;

    vec4 world_space_position = ReconstructWorldSpacePositionFromDepth(inverse_proj, inverse_view, texcoord, depth);

    vec3 tangent;
    vec3 bitangent;
    ComputeOrthonormalBasis(N, tangent, bitangent);

    const vec2 texel_size = vec2(1.0) / vec2(ssr_params.dimension.xy);
    const float texel_size_max = max(texel_size.x, texel_size.y);

    vec3 ray_origin = P + view_space_normal;
    
#ifdef ROUGHNESS_SCATTERING
    vec2 blue_noise_sample = vec2(
        SampleBlueNoise(int(coord.x), int(coord.y), 0, 0),
        SampleBlueNoise(int(coord.x), int(coord.y), 0, 1)
    );

    vec2 blue_noise_scaled = blue_noise_sample + float(scene.frame_counter % 256) * 1.618;
    const vec2 rnd = fmod(blue_noise_scaled, vec2(1.0));
    
    vec3 H = ImportanceSampleGGX(rnd, N, roughness);
    H = tangent * H.x + bitangent * H.y + N * H.z;

    vec3 ray_direction = reflect(-V, normalize((view * vec4(H, 0.0)).xyz));
#else
    vec3 ray_direction = reflect(normalize(ray_origin), view_space_normal);
#endif

    //discard if the ray is pointing directly towards the camera
    if (dot(ray_direction, -V) < 0.0) {
        imageStore(ssr_uvs, ivec2(coord), vec4(0.0));
        return;
    }

    vec2 hit_pixel;
    vec3 hit_point;
    float hit_weight;
    float num_iterations;

    bool intersect = TraceRays(ray_origin, ray_direction, hit_pixel, hit_point, hit_weight, num_iterations);

    float dist = distance(ray_origin, hit_point);

    float alpha = CalculateAlpha(num_iterations, hit_pixel, hit_point, dist, ray_direction) * float(intersect);

    alpha *= float(hit_pixel == saturate(hit_pixel));
    hit_pixel = saturate(hit_pixel);
    hit_pixel *= float(alpha > HYP_FMATH_EPSILON);

    imageStore(ssr_uvs, ivec2(coord), vec4(hit_pixel, 0.0, alpha));
}